---
description: Template for documenting brainstorm session outputs
---

# Brainstorm: [FEATURE_NAME] Improvements

**Date**: [YYYY-MM-DD]
**Agent**: zo.brainstorm (Reality Distortion Field Engineer)
**Session Duration**: [X minutes]
**Status**: [Complete ‚úÖ / Partial ‚ö†Ô∏è]

---

## üîç Research Context

**Focus**: [What we were investigating]
**Files Examined**: [N files]
**Git Commits Analyzed**: [N commits]

### Current State Analysis

- **Implementation**: [Key files and architecture]
- **Scale**: [LOC, components, users]
- **Recent Activity**: [Last 2-4 weeks of changes]

### Validated Pain Points

1. **[Critical Pain #1]** - [Evidence from code/users/metrics]

   - Impact: [Quantified cost]
   - Source: [Where this came from - git, feedback, profiling]

2. **[Medium Pain #2]** - [Evidence]

3. **[Minor Pain #3]** - [Evidence]

### Competitive Landscape

- **[Competitor 1]**: [Their approach, what we can learn]
- **[Competitor 2]**: [Their approach, what we can learn]
- **Our Opportunity**: [What we can do that they can't]

### Technical Constraints

- üö´ **Cannot do**: [Hard blockers]
- ‚ö†Ô∏è **Risky**: [Things to be careful with]
- ‚úÖ **Quick wins**: [Low-hanging fruit]

### First Principles Analysis

- **Core Problem**: [The REAL problem we're solving]
- **User Job-to-be-Done**: [Why users "hire" this feature]
- **North Star Metric**: [The ONE metric that matters]

**This research informed the [N] ideas below.**

---

## üí° Ideas Generated

### Accepted Ideas ([N] total)

#### 1. ‚úÖ [Idea Title] (Type: [Blue Sky üöÄ / Bedrock üèóÔ∏è / Strategic üéØ])

**Core Insight**: [Why this matters - data-backed fundamental truth]

**The Big Idea**: [What we're building - 2-3 sentences vision]

**10x Impact**:

- Before: [Current pain with metrics]
- After: [With this idea with metrics]
- The Math: [How it multiplies impact]

**Competitive Edge**: [What makes this different from competitors]

**First Principles**:

- Problem: [Fundamental user need]
- Why now: [Why existing solutions fail]
- Our approach: [Why this is architecturally right]

**Risks & Mitigation**:

- Risk 1: [Specific failure mode + mitigation]
- Risk 2: [Specific failure mode + mitigation]
- Success criteria: [Metric to track]

**Effort Estimate**:

- Optimistic: [X weeks]
- Realistic: [X √ó 1.5 weeks] ‚≠ê Use this
- Pessimistic: [X √ó 2 weeks]
- Dependencies: [What needs to exist]

**Reality Check**: [Honest assessment - would you bet your bonus on this?]

---

#### 2. ‚úÖ [Idea Title] (Type: [Blue Sky üöÄ / Bedrock üèóÔ∏è / Strategic üéØ])

*Repeat same structure as Idea 1*

---

#### [N]. ‚úÖ [Idea Title] (Type: [Blue Sky üöÄ / Bedrock üèóÔ∏è / Strategic üéØ])

*Repeat same structure*

---

### Rejected Ideas ([N] total)

- ‚ùå [Idea 1]: [Why rejected - not 10x, too risky, wrong timing]
- ‚ùå [Idea 2]: [Why rejected]
- ‚ùå [Idea 3]: [Why rejected]

---

## üéØ Prioritization Matrix

| Idea | Impact | Effort | Risk | Priority | Rationale |
|------|--------|--------|------|----------|-----------|
| #[N] [Title] | üî•üî•üî• | [X]w | Low | **P0** | [Why must-have] |
| #[N] [Title] | üî•üî• | [X]w | Med | **P1** | [Why should-have] |
| #[N] [Title] | üî• | [X]w | High | **P2** | [Why nice-to-have] |
| #[N] [Title] | üî• | [X]w | High | **P3** | [Strategic bet] |

**Priority Definitions**:

- **P0 (Must-Have)**: Blocking user value OR critical technical foundation. Do first.
- **P1 (Should-Have)**: Significant competitive advantage OR major quality-of-life. Do if time allows.
- **P2 (Nice-to-Have)**: Future-proofing OR exploratory. Do after P0/P1 complete.
- **P3 (Strategic Bet)**: Long-term investment OR unvalidated hypothesis. Requires separate discovery phase.

**Critical Path**: [Which ideas block other ideas? What's the dependency chain?]

---

## ‚è±Ô∏è Effort Reality Check

**Total Effort (Realistic Estimates)**: [X-Y engineering weeks]

**Breakdown by Type**:

- Blue Sky (Innovation): [X weeks]
- Bedrock (Foundation): [Y weeks]
- Strategic (Discovery): [Z weeks]

**Recommended Phasing** (for solo developer or small team):

### Phase 0: Research & Setup (Week 1-2)

- [ ] Design system audit
- [ ] Proof-of-concept for riskiest idea
- [ ] User interviews (if Strategic questions need validation)

### Phase 1: Foundation (Week 3-[X])

**Goal**: Stable, boring infrastructure

- [ ] [Bedrock Idea 1]
- [ ] [Bedrock Idea 2]
- [ ] [Bedrock Idea 3]

**Why first**: You can't build Blue Sky features on shaky foundation.

### Phase 2: Differentiation (Week [X]-[Y])

**Goal**: Competitive "wow" factor

- [ ] [Top Blue Sky Idea]
- [ ] [Second Blue Sky Idea]

**Why second**: Foundation lets you move fast without breaking things.

### Phase 3: Scale & Polish (Week [Y]-[Z])

**Goal**: Handle growth, optimize

- [ ] [Third Blue Sky Idea OR Performance optimizations]
- [ ] [Template system / content leverage]

**Why third**: You have users to optimize for now.

### Phase 4: Strategic Bets (Week [Z]+)

**Goal**: Long-term positioning

- [ ] [Strategic Idea 1 - IF validated]
- [ ] [Strategic Idea 2 - IF validated]

**Why last**: These require market validation, can't force timing.

**Risk Mitigation**:

- ‚ö†Ô∏è Add 25% buffer to each phase (Murphy's Law)
- üéØ Define 1 "escape hatch" per phase (what to cut if timeline slips)
- üö® Hard stop after Phase 2 if traction doesn't materialize

---

## ‚ö†Ô∏è Risk Register

### Technical Risks

1. **[Risk Category, e.g., "State Management Complexity"]**

   - **What**: [Specific risk]
   - **Probability**: [High/Med/Low]
   - **Impact**: [Critical/Major/Minor]
   - **Mitigation**: [What we'll do]
   - **Escape Hatch**: [Last resort if mitigation fails]

2. **[Risk Category]**

   - **What**: [Specific risk]
   - **Probability**: [High/Med/Low]
   - **Impact**: [Critical/Major/Minor]
   - **Mitigation**: [What we'll do]
   - **Escape Hatch**: [Last resort]

3. **[Risk Category]**

   - **What**: [Specific risk]
   - **Probability**: [High/Med/Low]
   - **Impact**: [Critical/Major/Minor]
   - **Mitigation**: [What we'll do]
   - **Escape Hatch**: [Last resort]

### Product Risks

1. **[Risk Category, e.g., "Feature Bloat"]**

   - **What**: [Specific risk]
   - **Probability**: [High/Med/Low]
   - **Impact**: [Critical/Major/Minor]
   - **Mitigation**: [What we'll do]
   - **Escape Hatch**: [Last resort]

2. **[Risk Category]**

   - **What**: [Specific risk]
   - **Probability**: [High/Med/Low]
   - **Impact**: [Critical/Major/Minor]
   - **Mitigation**: [What we'll do]
   - **Escape Hatch**: [Last resort]

### Market Risks

1. **[Risk Category, e.g., "Competitive Response"]**

   - **What**: [Specific risk]
   - **Probability**: [High/Med/Low]
   - **Impact**: [Critical/Major/Minor]
   - **Mitigation**: [Our defensibility]
   - **Unique Advantage**: [What they can't copy easily]

2. **[Risk Category]**

   - **What**: [Specific risk]
   - **Probability**: [High/Med/Low]
   - **Impact**: [Critical/Major/Minor]
   - **Mitigation**: [Our defensibility]
   - **Unique Advantage**: [What they can't copy easily]

---

## ü§î Strategic Questions (Open Decisions)

These are **genuine questions** that need resolution before committing resources. They are NOT proposals.

### Question 1: [Strategic Question Title]

**The Dilemma**: [What's the tension/trade-off?]

**Options on the Table**:

- **Option A**: [Approach 1]

  - Pros: [Benefits]
  - Cons: [Downsides]
  - Example: [Who's done this? How did it work out?]

- **Option B**: [Approach 2]

  - Pros: [Benefits]
  - Cons: [Downsides]
  - Example: [Who's done this? How did it work out?]

- **Option C**: [Approach 3 / Hybrid / "Wait and see"]

  - Pros: [Benefits]
  - Cons: [Downsides]

**What We Don't Know Yet** (Unknowns that need research):

1. [Unknown 1]
2. [Unknown 2]
3. [Unknown 3]

**Decision Framework**:

- **If** [Condition 1], then choose [Option X]
- **If** [Condition 2], then choose [Option Y]
- **If** [Neither condition met], then [Default action / more research needed]

**Timeline**: Make decision by [Date] OR when [Milestone reached]

**Who Decides**: [Who has authority? What's the process?]

---

### Question 2: [Strategic Question Title]

*Repeat same structure*

---

## üìä Session Stats

- **Ideas Presented**: 8
- **Accepted**: [N]
- **Rejected**: [N]
- **Refined**: [N times]
- **Session Duration**: [X minutes]

**Value Assessment** (if all P0/P1 shipped):

- **Estimated User Impact**: [Metric, e.g., "3-5x increase in story creation rate"]
- **Estimated Dev Time**: [X-Y weeks realistic]
- **Risk-Adjusted ROI**: [High/Medium/Low based on impact vs effort vs risk]

---

## üöÄ Recommended Next Steps

### Path A: Deep Dive on Specific Ideas ‚Üí Feature Spec

**When**: You want detailed specifications for accepted ideas

```bash
# Option 1: Specify ALL accepted ideas
/zo.specify.idea all

# Option 2: Specify specific ideas by ID
/zo.specify.idea 1,3,5

# Option 3: With design system integration (RECOMMENDED for UI/UX features)
/zo.specify.idea 1,3,5 --design
```

### Path B: Start Implementation Planning

**When**: You're ready to break ideas into executable tasks

```bash
# Create implementation plan for specific ideas
/zo.plan idea:1 idea:2

# Or plan entire feature
/zo.plan [feature-name]
```

### Path C: Validate Strategic Questions First

**When**: You have open Strategic questions that need research before committing

**Available Options**:

1. **Deep-dive with git history and code analysis**:
   ```bash
   # Search for related patterns and past decisions
   git log --oneline --all --grep="[keyword]" | head -20
   
   # Analyze existing implementations
   grep -r "[keyword]" --include="*.ts" --include="*.tsx" .
   ```

2. **Re-brainstorm with research focus**:
   ```bash
   /zo.brainstorm "research: [strategic question topic] - analyze competitors, user needs, and technical feasibility"
   ```

3. **Document research gaps in the Strategic Question itself**:
   - Add "What We Don't Know Yet" section with specific research questions
   - Create a separate research document in `docs/research/`
   - Link it from the strategic question
   ```markdown
   **Research Needed**:
   
   - See `docs/research/[topic]-analysis.md` for initial findings
   - Key question to answer: [specific question]
   ```

### Path D: Continue Exploring Alternatives

**When**: You want to explore variations before committing

```bash
# Brainstorm alternatives for specific idea
/zo.brainstorm "alternative approaches to idea #[N]"

# Or explore adjacent problem space
/zo.brainstorm "what if we approached [problem] from [different angle]"
```

### Path E: Quick Win - Start with Foundation

**When**: You want to ship something small to validate assumptions

**Recommended Quick Win** (Week 1-2):

1. Pick ONE Bedrock idea (usually highest priority)
2. Implement minimal viable version
3. Get user feedback before building more

```bash
# Specify just the foundation piece
/zo.specify.idea [bedrock-idea-id]
```

---

## üéì Decision Guide

**Still not sure which path?** Answer these questions:

1. **Do you have validated product-market fit?**

   - ‚úÖ Yes ‚Üí Path A or B (build features)
   - ‚ùå No ‚Üí Path C (validate first)

2. **Are Strategic questions blocking P0 ideas?**

   - ‚úÖ Yes ‚Üí Path C (resolve questions first)
   - ‚ùå No ‚Üí Path A or B

3. **Is the team 100% aligned on direction?**

   - ‚úÖ Yes ‚Üí Path B (start building)
   - ‚ùå No ‚Üí Path A (get detailed specs to debate)

4. **Do you have < 2 weeks before next demo/launch?**

   - ‚úÖ Yes ‚Üí Path E (ship quick win)
   - ‚ùå No ‚Üí Path A or B

**Default Recommendation**: Path A with `--design` flag for ideas with UI components. This gives you crisp specifications to discuss with team before committing to implementation.

---

## üí¨ Feedback & Iteration

This brainstorm is a living document. As you implement ideas or learn more:

1. **Mark ideas as shipped**: Add ‚úÖ and date when complete
2. **Update risk register**: Mark risks as resolved or add new ones discovered
3. **Revise effort estimates**: Actual vs estimated helps calibrate future brainstorms
4. **Track impact**: Did the idea move the North Star Metric as predicted?

**Re-brainstorm When**:

- User feedback contradicts assumptions (e.g., feature nobody uses)
- Technical constraints change (e.g., new framework available)
- Market shifts (e.g., competitor launches similar feature)
- Strategic questions get answered (may unlock new ideas)

---

**Generated by**: zo.brainstorm (Reality Distortion Field Engineer)
**Review this doc in**: 30 days OR after shipping 3+ ideas
**Questions?**: Run `/zo.brainstorm --help` or ping the team

---

## Template Usage Notes

### Filling This Template

1. **Replace all bracketed placeholders** with actual content
2. **Data-driven claims**: Every assertion needs evidence (git commits, user feedback, metrics, competitive examples)
3. **10x or nothing**: Ensure accepted ideas pass the 10x test (not just incremental improvements)
4. **Realistic estimates**: Apply 1.5x multiplier to optimistic estimates
5. **Strategic questions stay questions**: Don't propose solutions in the question section

### Quality Checklist

Before finalizing:

- [ ] Research Context section present with actual data
- [ ] Every accepted idea has full detail (not just title)
- [ ] Prioritization matrix with clear P0/P1/P2/P3
- [ ] Effort estimates are realistic (1.5x multiplier applied)
- [ ] Risk register covers technical + product + market
- [ ] Strategic questions remain questions (not proposals)
- [ ] Next steps offer multiple paths (not just one)
- [ ] Session stats included
- [ ] Persona voice maintained (data-driven, direct, first principles)

### Common Patterns

**Blue Sky Ideas** (3x required):
- Focus on UX delight and "wow" factors
- Must make users say "whoa" not just "oh, nice"
- Need data/examples from successful products

**Bedrock Ideas** (3x required):
- Focus on refactoring, security, performance, tech debt
- Must pass: "Would removing this cause a P0 incident?"
- Need concrete metrics on current pain

**Strategic Questions** (2x required):
- Focus on long-term scalability, market fit, architectural pivots
- Must be genuine open questions with trade-offs
- Include decision framework and timeline
